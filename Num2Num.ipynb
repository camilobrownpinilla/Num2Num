{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence as pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.src from https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\n",
      "\n",
      "Downloading train.tgt from https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\n",
      "\n",
      "Downloading dev.src from https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\n",
      "\n",
      "Downloading dev.tgt from https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\n",
      "\n",
      "Downloading test.src from https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\n",
      "\n",
      "Downloading test.tgt from https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import wget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "\n",
    "# Download the dataset\n",
    "files = ['train.src', 'train.tgt', 'dev.src', 'dev.tgt', 'test.src', 'test.tgt']\n",
    "source = \"https://github.com/nlp-course/data/raw/refs/heads/master/Words2Num/\"\n",
    "os.makedirs('./data/', exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    print(f'Downloading {file} from {source}')\n",
    "    wget.download(source + file, out='./data/')\n",
    "    print(\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    src_in_file = f'./data/{split}.src'\n",
    "    tgt_in_file = f'./data/{split}.tgt'\n",
    "    out_file = f'./data/{split}.csv'\n",
    "    \n",
    "    with open(src_in_file, 'r') as f_src_in, open(tgt_in_file, 'r') as f_tgt_in:\n",
    "        with open(out_file, 'w') as f_out:\n",
    "            src, tgt= [], []\n",
    "            writer = csv.writer(f_out)\n",
    "            writer.writerow(('src','tgt'))\n",
    "            for src_line, tgt_line in zip(f_src_in, f_tgt_in):\n",
    "                writer.writerow((src_line.strip(), tgt_line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2959106d17440beb5821edbf94722f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c2c75bbf914593b93d4eab65c26196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cefb16c92544ff9a8379d19635ea47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522ffa38d3b6456f86319c6ec3d9a00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc7a623dca44b9b8f4bcc1fd7fc9afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": f\"./data/train.csv\",\n",
    "        \"val\": f\"./data/dev.csv\",\n",
    "        \"test\": f\"./data/test.csv\",\n",
    "    },\n",
    ")\n",
    "\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "val_data = dataset['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilopinilla/anaconda3/envs/cs1870_env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizers and add special tokens\n",
    "unk_token = '[UNK]'\n",
    "pad_token = '[PAD]'\n",
    "bos_token = '<bos>'\n",
    "eos_token = '<eos>'\n",
    "src_tokenizer = Tokenizer(WordLevel(unk_token=unk_token))\n",
    "src_tokenizer.pre_tokenizer = WhitespaceSplit()\n",
    "\n",
    "src_trainer = WordLevelTrainer(special_tokens=[pad_token, unk_token])\n",
    "src_tokenizer.train_from_iterator(train_data['src'], trainer=src_trainer)\n",
    "\n",
    "tgt_tokenizer = Tokenizer(WordLevel(unk_token=unk_token))\n",
    "tgt_tokenizer.pre_tokenizer = WhitespaceSplit()\n",
    "\n",
    "tgt_trainer = WordLevelTrainer(special_tokens=[pad_token, unk_token, bos_token, eos_token])\n",
    "\n",
    "tgt_tokenizer.train_from_iterator(train_data['tgt'], trainer=tgt_trainer)\n",
    "\n",
    "tgt_tokenizer.post_processor = \\\n",
    "  TemplateProcessing(single=f\"{bos_token} $A {eos_token}\",\n",
    "                     special_tokens=[(bos_token, \n",
    "                                      tgt_tokenizer.token_to_id(bos_token)), \n",
    "                                     (eos_token,\n",
    "                                      tgt_tokenizer.token_to_id(eos_token))])\n",
    "\n",
    "# Wrap with PreTrainedTokenizerFast for compatability with datasets\n",
    "hf_src_tokenizer = PreTrainedTokenizerFast(tokenizer_object=src_tokenizer,\n",
    "                                           pad_token=pad_token,\n",
    "                                           unk_token=unk_token)\n",
    "hf_tgt_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tgt_tokenizer,\n",
    "                                           pad_token=pad_token, \n",
    "                                           unk_token=unk_token, \n",
    "                                           bos_token=bos_token,\n",
    "                                           eos_token=eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596727088ef7499dac5035bcedbed097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/65022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a36a82171547ab9dd6a7d0fcd1ca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7400bd468543ac870dde3df52f5357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode data\n",
    "def encode(example):\n",
    "    example['src_ids'] = hf_src_tokenizer(example['src']).input_ids\n",
    "    example['tgt_ids'] = hf_tgt_tokenizer(example['tgt']).input_ids\n",
    "    return example\n",
    "\n",
    "train_data = train_data.map(encode)\n",
    "val_data = val_data.map(encode)\n",
    "test_data = test_data.map(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "BATCH_SIZE = 32  \n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "src_vocab = hf_src_tokenizer.get_vocab()\n",
    "tgt_vocab = hf_tgt_tokenizer.get_vocab()\n",
    "\n",
    "# Defines how to batch a list of examples together\n",
    "def collate_fn(examples):\n",
    "    batch = {}\n",
    "    bsz = len(examples)\n",
    "    src_ids, tgt_ids = [], []\n",
    "    for example in examples:\n",
    "        src_ids.append(example['src_ids'])\n",
    "        tgt_ids.append(example['tgt_ids'])\n",
    "\n",
    "    src_len = torch.LongTensor([len(word_ids) for word_ids in src_ids]).to(device)\n",
    "    src_max_length = max(src_len)\n",
    "    tgt_max_length = max([len(word_ids) for word_ids in tgt_ids])\n",
    "\n",
    "    src_batch = torch.zeros(bsz, src_max_length).long().fill_(src_vocab[pad_token]).to(device)\n",
    "    tgt_batch = torch.zeros(bsz, tgt_max_length).long().fill_(tgt_vocab[pad_token]).to(device)\n",
    "    for b in range(bsz):\n",
    "        src_batch[b][:len(src_ids[b])] = torch.LongTensor(src_ids[b]).to(device)\n",
    "        tgt_batch[b][:len(tgt_ids[b])] = torch.LongTensor(tgt_ids[b]).to(device)\n",
    "    \n",
    "    batch['src_lengths'] = src_len\n",
    "    batch['src_ids'] = src_batch\n",
    "    batch['tgt_ids'] = tgt_batch\n",
    "    return batch\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(train_data, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         shuffle=True, \n",
    "                                         collate_fn=collate_fn)\n",
    "val_iter = torch.utils.data.DataLoader(val_data, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       shuffle=False, \n",
    "                                       collate_fn=collate_fn)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, \n",
    "                                        batch_size=TEST_BATCH_SIZE, \n",
    "                                        shuffle=False, \n",
    "                                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will consist of a bi-directional LSTM encoder feeding to  a uni-directional LSTM decoder. This of course generates a shape mismatch between the output of the encoder vs the expected input of the decoder. We address this a function 'reshape', built from the assumption that the shape of the encoder output will be `(num_layers * directions, bsz, hidden_size)`, from the pytorch documentaiton of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(t: torch.Tensor, layer_size, bsz, hidden_size) -> torch.Tensor:\n",
    "    t = t.reshape([2, layer_size, bsz, hidden_size // 2])\n",
    "    t = torch.cat([t[0], t[1]], dim=-1)\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            src_tokenizer,\n",
    "            tgt_tokenizer,\n",
    "            embedding_size=64,\n",
    "            hidden_size=64,\n",
    "            layers=2,\n",
    "    ):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        \n",
    "        self.vocab_size_src = len(src_tokenizer)\n",
    "        self.vocab_size_tgt = len(tgt_tokenizer)\n",
    "\n",
    "        self.padding_id_src = self.src_tokenizer.pad_token_id\n",
    "        self.padding_id_tgt = self.tgt_tokenizer.pad_token_id\n",
    "        self.bos_id = self.tgt_tokenizer.bos_token_id\n",
    "        self.eos_id = self.tgt_tokenizer.bos_token_id\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "\n",
    "        self.src_embeddings = nn.Embedding(self.vocab_size_src, embedding_size)\n",
    "        self.tgt_embeddings = nn.Embedding(self.vocab_size_tgt, embedding_size)\n",
    "\n",
    "        # RNN cells\n",
    "        self.encoder_rnn = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size // 2,  # to match decoder hidden size\n",
    "            batch_first=True,\n",
    "            num_layers=layers,\n",
    "            bidirectional=True,  # bidirectional encoder\n",
    "        )\n",
    "        self.decoder_rnn = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=layers,\n",
    "            bidirectional=False,  # unidirectional decoder\n",
    "        )\n",
    "\n",
    "        # Final projection layer\n",
    "        self.hidden2output = nn.Linear(hidden_size, self.vocab_size_tgt)\n",
    "\n",
    "        # Create loss function\n",
    "        self.loss_function = nn.CrossEntropyLoss(\n",
    "            reduction=\"sum\", ignore_index=self.padding_id_tgt\n",
    "        )\n",
    "\n",
    "    def forward_encoder(self, src, src_lengths):\n",
    "        \"\"\"Encodes 'src'. Returns hidden state and context state\n",
    "\n",
    "        Args:\n",
    "            src: input batch of size (bsz, max_src_len)\n",
    "            src_lengths: lengths of sources of size (bsz)\n",
    "        \"\"\"\n",
    "        bsz = src.shape[0]\n",
    "        src_embeddings = self.src_embeddings(src)\n",
    "        packed = pack(src_embeddings, src_lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (h, c) = self.encoder_rnn(packed)\n",
    "        h = reshape(h, self.layers, bsz, self.hidden_size)\n",
    "        c = reshape(c, self.layers, bsz, self.hidden_size)\n",
    "\n",
    "        return h, c\n",
    "    \n",
    "    def forward_decoder(self, encoder_final_state, tgt_in):\n",
    "        tgt_embeddings = self.tgt_embeddings(tgt_in)\n",
    "        out, _ = self.decoder_rnn(tgt_embeddings, encoder_final_state)\n",
    "        return self.hidden2output(out)\n",
    "    \n",
    "    def forward(self, src, src_lengths, tgt_in):\n",
    "        encoder_final_state = self.forward_encoder(src, src_lengths)\n",
    "        logits = self.forward_decoder(encoder_final_state, tgt_in)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2032/2032 [00:38<00:00, 52.41it/s]\n",
      "100%|██████████| 2032/2032 [00:38<00:00, 52.97it/s]\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder(hf_src_tokenizer,\n",
    "                       hf_tgt_tokenizer,).to(device)\n",
    "\n",
    "epochs = 2\n",
    "lr = 2e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_words = 0\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_iter):\n",
    "        model.zero_grad()\n",
    "        tgt = batch[\"tgt_ids\"]\n",
    "        src = batch[\"src_ids\"]\n",
    "        src_lengths = batch['src_lengths']\n",
    "\n",
    "        # Remove eos\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        # Remove bos\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        bsz = src.size(0)\n",
    "\n",
    "        logits = model.forward(src, src_lengths, tgt_in)\n",
    "        loss = model.loss_function(\n",
    "            logits.reshape(-1, model.vocab_size_tgt), tgt_out.reshape(-1)\n",
    "        )\n",
    "\n",
    "        total_words += tgt_out.ne(model.padding_id_tgt).float().sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.div(bsz).backward()\n",
    "        optim.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_iter):\n",
    "    \"\"\"Return the accuracy of the 'model' on 'test_iter'\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1870_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
